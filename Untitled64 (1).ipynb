{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------HEART DISEASE DETECTION-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "dataset = pd.read_csv(\"C://Users//Akansha//Downloads//heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age:\t\t\tage\n",
      "sex:\t\t\t1: male, 0: female\n",
      "cp:\t\t\tchest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\n",
      "trestbps:\t\t\tresting blood pressure\n",
      "chol:\t\t\t serum cholestoral in mg/dl\n",
      "fbs:\t\t\tfasting blood sugar > 120 mg/dl\n",
      "restecg:\t\t\tresting electrocardiographic results (values 0,1,2)\n",
      "thalach:\t\t\t maximum heart rate achieved\n",
      "exang:\t\t\texercise induced angina\n",
      "oldpeak:\t\t\toldpeak = ST depression induced by exercise relative to rest\n",
      "slope:\t\t\tthe slope of the peak exercise ST segment\n",
      "ca:\t\t\tnumber of major vessels (0-3) colored by flourosopy\n",
      "thal:\t\t\tthal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n"
     ]
    }
   ],
   "source": [
    "info = [\"age\",\"1: male, 0: female\",\"chest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\",\"resting blood pressure\",\" serum cholestoral in mg/dl\",\"fasting blood sugar > 120 mg/dl\",\"resting electrocardiographic results (values 0,1,2)\",\" maximum heart rate achieved\",\"exercise induced angina\",\"oldpeak = ST depression induced by exercise relative to rest\",\"the slope of the peak exercise ST segment\",\"number of major vessels (0-3) colored by flourosopy\",\"thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\"]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(info)):\n",
    "    print(dataset.columns[i]+\":\\t\\t\\t\"+info[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Distribution : Patient with and without heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    165\n",
      "0    138\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = dataset[\"target\"]\n",
    "\n",
    "sns.countplot(y)\n",
    "\n",
    "\n",
    "target_temp = dataset.target.value_counts()\n",
    "\n",
    "print(target_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of patience without heart problems: 45.54\n",
      "Percentage of patience with heart problems: 54.46\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of patience without heart problems: \"+str(round(target_temp[0]*100/303,2)))\n",
    "print(\"Percentage of patience with heart problems: \"+str(round(target_temp[1]*100/303,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x216d4930248>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(dataset[\"sex\"],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x216d597e588>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(dataset[\"cp\"],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors = dataset.drop(\"target\",axis=1)\n",
    "target = dataset[\"target\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 67.21 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,Y_train)\n",
    "Y_pred_knn=knn.predict(X_test)\n",
    "score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_accuracy = 0\n",
    "\n",
    "\n",
    "for x in range(200):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(X_train,Y_train)\n",
    "    Y_pred_dt = dt.predict(X_test)\n",
    "    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "        \n",
    "#print(max_accuracy)\n",
    "#print(best_x)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(X_train,Y_train)\n",
    "Y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 81.97 %\n"
     ]
    }
   ],
   "source": [
    "score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, Masking, TimeDistributed\n",
    "from tensorflow. keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=13))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 242 samples\n",
      "Epoch 1/300\n",
      "242/242 [==============================] - 2s 10ms/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 2/300\n",
      "242/242 [==============================] - 0s 394us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 3/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 4/300\n",
      "242/242 [==============================] - 0s 134us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 5/300\n",
      "242/242 [==============================] - 0s 113us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 6/300\n",
      "242/242 [==============================] - 0s 133us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 7/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 8/300\n",
      "242/242 [==============================] - 0s 104us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 9/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 10/300\n",
      "242/242 [==============================] - 0s 121us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 11/300\n",
      "242/242 [==============================] - 0s 132us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 12/300\n",
      "242/242 [==============================] - 0s 134us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 13/300\n",
      "242/242 [==============================] - 0s 118us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 14/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 15/300\n",
      "242/242 [==============================] - ETA: 0s - loss: 8.6765 - accuracy: 0.43 - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 16/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 17/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 18/300\n",
      "242/242 [==============================] - 0s 102us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 19/300\n",
      "242/242 [==============================] - 0s 128us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 20/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 21/300\n",
      "242/242 [==============================] - 0s 113us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 22/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 23/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 24/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 25/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 26/300\n",
      "242/242 [==============================] - 0s 101us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 27/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 28/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 29/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 30/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 31/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 32/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 33/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 34/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 35/300\n",
      "242/242 [==============================] - 0s 99us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 36/300\n",
      "242/242 [==============================] - 0s 101us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 37/300\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 38/300\n",
      "242/242 [==============================] - 0s 96us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 39/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 40/300\n",
      "242/242 [==============================] - 0s 120us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 41/300\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 42/300\n",
      "242/242 [==============================] - ETA: 0s - loss: 6.2664 - accuracy: 0.59 - 0s 92us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 43/300\n",
      "242/242 [==============================] - 0s 98us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 44/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 45/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 46/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 47/300\n",
      "242/242 [==============================] - 0s 102us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 48/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 49/300\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 50/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 51/300\n",
      "242/242 [==============================] - 0s 124us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 52/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 53/300\n",
      "242/242 [==============================] - 0s 102us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 54/300\n",
      "242/242 [==============================] - 0s 95us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 55/300\n",
      "242/242 [==============================] - 0s 95us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 56/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 57/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 58/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 59/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 60/300\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 61/300\n",
      "242/242 [==============================] - 0s 113us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 62/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 63/300\n",
      "242/242 [==============================] - 0s 99us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 64/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 65/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 66/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 67/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 68/300\n",
      "242/242 [==============================] - 0s 98us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 69/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 70/300\n",
      "242/242 [==============================] - 0s 101us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 71/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 72/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 73/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 74/300\n",
      "242/242 [==============================] - 0s 113us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 75/300\n",
      "242/242 [==============================] - 0s 90us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 76/300\n",
      "242/242 [==============================] - 0s 89us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 77/300\n",
      "242/242 [==============================] - 0s 142us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 78/300\n",
      "242/242 [==============================] - 0s 134us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 79/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 80/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 81/300\n",
      "242/242 [==============================] - 0s 120us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 82/300\n",
      "242/242 [==============================] - 0s 145us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 83/300\n",
      "242/242 [==============================] - 0s 118us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 84/300\n",
      "242/242 [==============================] - 0s 120us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 85/300\n",
      "242/242 [==============================] - 0s 109us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 86/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 87/300\n",
      "242/242 [==============================] - 0s 156us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 88/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 89/300\n",
      "242/242 [==============================] - 0s 128us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 90/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 91/300\n",
      "242/242 [==============================] - 0s 135us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 92/300\n",
      "242/242 [==============================] - 0s 133us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 93/300\n",
      "242/242 [==============================] - 0s 145us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 94/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 95/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 96/300\n",
      "242/242 [==============================] - 0s 128us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 97/300\n",
      "242/242 [==============================] - 0s 135us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 98/300\n",
      "242/242 [==============================] - 0s 130us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 99/300\n",
      "242/242 [==============================] - 0s 140us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 100/300\n",
      "242/242 [==============================] - 0s 139us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 101/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 102/300\n",
      "242/242 [==============================] - 0s 124us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 103/300\n",
      "242/242 [==============================] - 0s 146us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 104/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 105/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 106/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 107/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 108/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 109/300\n",
      "242/242 [==============================] - 0s 137us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 110/300\n",
      "242/242 [==============================] - 0s 128us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 111/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 112/300\n",
      "242/242 [==============================] - 0s 126us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 113/300\n",
      "242/242 [==============================] - 0s 123us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 114/300\n",
      "242/242 [==============================] - 0s 121us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 115/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 116/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 117/300\n",
      "242/242 [==============================] - 0s 137us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 118/300\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 119/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 120/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 121/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 122/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 123/300\n",
      "242/242 [==============================] - 0s 93us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 124/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 125/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 126/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 127/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 128/300\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 129/300\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 130/300\n",
      "242/242 [==============================] - 0s 96us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 131/300\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 132/300\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 133/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 134/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 135/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 136/300\n",
      "242/242 [==============================] - 0s 134us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 137/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 138/300\n",
      "242/242 [==============================] - 0s 129us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 139/300\n",
      "242/242 [==============================] - 0s 102us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 140/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 141/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 142/300\n",
      "242/242 [==============================] - 0s 92us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 143/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 144/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 145/300\n",
      "242/242 [==============================] - 0s 104us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 146/300\n",
      "242/242 [==============================] - 0s 86us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 147/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 148/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 149/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 150/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 151/300\n",
      "242/242 [==============================] - 0s 104us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 152/300\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 153/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 154/300\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 155/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 156/300\n",
      "242/242 [==============================] - 0s 140us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 157/300\n",
      "242/242 [==============================] - 0s 118us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 158/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 159/300\n",
      "242/242 [==============================] - 0s 133us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 160/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 161/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 162/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 163/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 164/300\n",
      "242/242 [==============================] - 0s 138us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 165/300\n",
      "242/242 [==============================] - 0s 129us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 166/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 167/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 168/300\n",
      "242/242 [==============================] - 0s 93us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 169/300\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 170/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 171/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 172/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 173/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 174/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 175/300\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 176/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 177/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 178/300\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 179/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 180/300\n",
      "242/242 [==============================] - 0s 92us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 181/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 182/300\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 183/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 184/300\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 185/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 186/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 187/300\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 188/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 189/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 190/300\n",
      "242/242 [==============================] - 0s 89us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 191/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 192/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 193/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 194/300\n",
      "242/242 [==============================] - 0s 109us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 195/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 196/300\n",
      "242/242 [==============================] - 0s 89us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 197/300\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 198/300\n",
      "242/242 [==============================] - 0s 113us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 199/300\n",
      "242/242 [==============================] - 0s 128us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 200/300\n",
      "242/242 [==============================] - 0s 126us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 201/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 202/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 203/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 204/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 205/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 206/300\n",
      "242/242 [==============================] - 0s 83us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 207/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 208/300\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 209/300\n",
      "242/242 [==============================] - 0s 84us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 210/300\n",
      "242/242 [==============================] - 0s 130us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 211/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 212/300\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 213/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 214/300\n",
      "242/242 [==============================] - 0s 118us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 215/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 216/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 217/300\n",
      "242/242 [==============================] - 0s 99us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 218/300\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 219/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 220/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 221/300\n",
      "242/242 [==============================] - 0s 104us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 222/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 223/300\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 224/300\n",
      "242/242 [==============================] - 0s 79us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 225/300\n",
      "242/242 [==============================] - 0s 120us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 226/300\n",
      "242/242 [==============================] - 0s 132us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 227/300\n",
      "242/242 [==============================] - 0s 118us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 228/300\n",
      "242/242 [==============================] - 0s 137us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 229/300\n",
      "242/242 [==============================] - 0s 95us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 230/300\n",
      "242/242 [==============================] - 0s 93us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 231/300\n",
      "242/242 [==============================] - 0s 101us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 232/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 233/300\n",
      "242/242 [==============================] - 0s 127us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 234/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 235/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 236/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 237/300\n",
      "242/242 [==============================] - 0s 118us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 238/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 239/300\n",
      "242/242 [==============================] - 0s 124us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 240/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 241/300\n",
      "242/242 [==============================] - 0s 128us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 242/300\n",
      "242/242 [==============================] - 0s 150us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 243/300\n",
      "242/242 [==============================] - 0s 109us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 244/300\n",
      "242/242 [==============================] - 0s 141us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 245/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 246/300\n",
      "242/242 [==============================] - 0s 120us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 247/300\n",
      "242/242 [==============================] - 0s 122us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 248/300\n",
      "242/242 [==============================] - 0s 123us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 249/300\n",
      "242/242 [==============================] - 0s 91us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 250/300\n",
      "242/242 [==============================] - 0s 123us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 251/300\n",
      "242/242 [==============================] - 0s 121us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 252/300\n",
      "242/242 [==============================] - 0s 104us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 253/300\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 254/300\n",
      "242/242 [==============================] - 0s 105us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 255/300\n",
      "242/242 [==============================] - 0s 136us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 256/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 257/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 258/300\n",
      "242/242 [==============================] - 0s 120us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 259/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 260/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 261/300\n",
      "242/242 [==============================] - 0s 113us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 262/300\n",
      "242/242 [==============================] - 0s 124us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 263/300\n",
      "242/242 [==============================] - 0s 133us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 264/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 265/300\n",
      "242/242 [==============================] - 0s 121us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 266/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 267/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 268/300\n",
      "242/242 [==============================] - 0s 102us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 269/300\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 270/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 271/300\n",
      "242/242 [==============================] - 0s 117us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 272/300\n",
      "242/242 [==============================] - 0s 132us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 273/300\n",
      "242/242 [==============================] - 0s 143us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 274/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 275/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 276/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 277/300\n",
      "242/242 [==============================] - 0s 103us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 278/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 279/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 280/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 281/300\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 282/300\n",
      "242/242 [==============================] - 0s 107us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 283/300\n",
      "242/242 [==============================] - 0s 115us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 284/300\n",
      "242/242 [==============================] - 0s 119us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 285/300\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 286/300\n",
      "242/242 [==============================] - 0s 112us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 287/300\n",
      "242/242 [==============================] - 0s 102us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 288/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 289/300\n",
      "242/242 [==============================] - 0s 109us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 290/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 291/300\n",
      "242/242 [==============================] - 0s 87us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 292/300\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 293/300\n",
      "242/242 [==============================] - 0s 100us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 294/300\n",
      "242/242 [==============================] - 0s 114us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 295/300\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 296/300\n",
      "242/242 [==============================] - 0s 110us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 297/300\n",
      "242/242 [==============================] - 0s 121us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 298/300\n",
      "242/242 [==============================] - 0s 91us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 299/300\n",
      "242/242 [==============================] - 0s 116us/sample - loss: 8.3499 - accuracy: 0.4587\n",
      "Epoch 300/300\n",
      "242/242 [==============================] - 0s 108us/sample - loss: 8.3499 - accuracy: 0.4587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x216dcbbfe88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "Y_pred_nn = model.predict(X_test)\n",
    "rounded = [round(x[0]) for x in Y_pred_nn]\n",
    "Y_pred_nn = rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Deep Network is: 94.26 %\n"
     ]
    }
   ],
   "source": [
    "score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100+50,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Deep Network is: \"+str(score_nn)+\" %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CANCER PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#importing our cancer dataset\n",
    "data = pd.read_csv('C://Users//Akansha//Downloads//data (1).csv')\n",
    "del data['Unnamed: 32']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, Masking, TimeDistributed, Dropout\n",
    "from tensorflow. keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=30))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples\n",
      "Epoch 1/250\n",
      "512/512 [==============================] - 2s 3ms/sample - loss: 1.0203 - accuracy: 0.5410\n",
      "Epoch 2/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.7202 - accuracy: 0.6504\n",
      "Epoch 3/250\n",
      "512/512 [==============================] - 0s 136us/sample - loss: 0.5210 - accuracy: 0.7559\n",
      "Epoch 4/250\n",
      "512/512 [==============================] - 0s 127us/sample - loss: 0.3995 - accuracy: 0.8457\n",
      "Epoch 5/250\n",
      "512/512 [==============================] - 0s 150us/sample - loss: 0.3219 - accuracy: 0.8848\n",
      "Epoch 6/250\n",
      "512/512 [==============================] - 0s 118us/sample - loss: 0.2717 - accuracy: 0.9062\n",
      "Epoch 7/250\n",
      "512/512 [==============================] - 0s 122us/sample - loss: 0.2357 - accuracy: 0.9180\n",
      "Epoch 8/250\n",
      "512/512 [==============================] - 0s 113us/sample - loss: 0.2100 - accuracy: 0.9297\n",
      "Epoch 9/250\n",
      "512/512 [==============================] - 0s 184us/sample - loss: 0.1899 - accuracy: 0.9375\n",
      "Epoch 10/250\n",
      "512/512 [==============================] - 0s 154us/sample - loss: 0.1751 - accuracy: 0.9414\n",
      "Epoch 11/250\n",
      "512/512 [==============================] - 0s 141us/sample - loss: 0.1622 - accuracy: 0.9434\n",
      "Epoch 12/250\n",
      "512/512 [==============================] - 0s 155us/sample - loss: 0.1521 - accuracy: 0.9531\n",
      "Epoch 13/250\n",
      "512/512 [==============================] - 0s 150us/sample - loss: 0.1439 - accuracy: 0.9551\n",
      "Epoch 14/250\n",
      "512/512 [==============================] - 0s 125us/sample - loss: 0.1362 - accuracy: 0.9551\n",
      "Epoch 15/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.1297 - accuracy: 0.9551\n",
      "Epoch 16/250\n",
      "512/512 [==============================] - 0s 161us/sample - loss: 0.1243 - accuracy: 0.9551\n",
      "Epoch 17/250\n",
      "512/512 [==============================] - 0s 132us/sample - loss: 0.1190 - accuracy: 0.9551\n",
      "Epoch 18/250\n",
      "512/512 [==============================] - 0s 143us/sample - loss: 0.1145 - accuracy: 0.9590\n",
      "Epoch 19/250\n",
      "512/512 [==============================] - 0s 136us/sample - loss: 0.1103 - accuracy: 0.9590\n",
      "Epoch 20/250\n",
      "512/512 [==============================] - 0s 142us/sample - loss: 0.1066 - accuracy: 0.9590\n",
      "Epoch 21/250\n",
      "512/512 [==============================] - 0s 110us/sample - loss: 0.1030 - accuracy: 0.9648\n",
      "Epoch 22/250\n",
      "512/512 [==============================] - 0s 142us/sample - loss: 0.0999 - accuracy: 0.9668\n",
      "Epoch 23/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0968 - accuracy: 0.9688\n",
      "Epoch 24/250\n",
      "512/512 [==============================] - 0s 119us/sample - loss: 0.0940 - accuracy: 0.9727\n",
      "Epoch 25/250\n",
      "512/512 [==============================] - 0s 116us/sample - loss: 0.0916 - accuracy: 0.9746\n",
      "Epoch 26/250\n",
      "512/512 [==============================] - 0s 112us/sample - loss: 0.0890 - accuracy: 0.9766\n",
      "Epoch 27/250\n",
      "512/512 [==============================] - 0s 106us/sample - loss: 0.0869 - accuracy: 0.9785\n",
      "Epoch 28/250\n",
      "512/512 [==============================] - 0s 145us/sample - loss: 0.0847 - accuracy: 0.9785 - loss: 0.0872 - accuracy: 0.97\n",
      "Epoch 29/250\n",
      "512/512 [==============================] - 0s 123us/sample - loss: 0.0829 - accuracy: 0.9785\n",
      "Epoch 30/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0810 - accuracy: 0.9785\n",
      "Epoch 31/250\n",
      "512/512 [==============================] - 0s 124us/sample - loss: 0.0794 - accuracy: 0.9824\n",
      "Epoch 32/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0777 - accuracy: 0.9824\n",
      "Epoch 33/250\n",
      "512/512 [==============================] - 0s 111us/sample - loss: 0.0762 - accuracy: 0.9824\n",
      "Epoch 34/250\n",
      "512/512 [==============================] - 0s 110us/sample - loss: 0.0748 - accuracy: 0.9844\n",
      "Epoch 35/250\n",
      "512/512 [==============================] - 0s 131us/sample - loss: 0.0736 - accuracy: 0.9844\n",
      "Epoch 36/250\n",
      "512/512 [==============================] - 0s 111us/sample - loss: 0.0723 - accuracy: 0.9824\n",
      "Epoch 37/250\n",
      "512/512 [==============================] - 0s 106us/sample - loss: 0.0710 - accuracy: 0.9824\n",
      "Epoch 38/250\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 0.0699 - accuracy: 0.9824\n",
      "Epoch 39/250\n",
      "512/512 [==============================] - 0s 150us/sample - loss: 0.0687 - accuracy: 0.9824\n",
      "Epoch 40/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0679 - accuracy: 0.9824\n",
      "Epoch 41/250\n",
      "512/512 [==============================] - 0s 131us/sample - loss: 0.0669 - accuracy: 0.9844\n",
      "Epoch 42/250\n",
      "512/512 [==============================] - 0s 147us/sample - loss: 0.0658 - accuracy: 0.9844\n",
      "Epoch 43/250\n",
      "512/512 [==============================] - 0s 118us/sample - loss: 0.0649 - accuracy: 0.9844\n",
      "Epoch 44/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0641 - accuracy: 0.9844\n",
      "Epoch 45/250\n",
      "512/512 [==============================] - 0s 116us/sample - loss: 0.0633 - accuracy: 0.9844\n",
      "Epoch 46/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0624 - accuracy: 0.9844\n",
      "Epoch 47/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0616 - accuracy: 0.9844\n",
      "Epoch 48/250\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 0.0609 - accuracy: 0.9844\n",
      "Epoch 49/250\n",
      "512/512 [==============================] - 0s 142us/sample - loss: 0.0602 - accuracy: 0.9844\n",
      "Epoch 50/250\n",
      "512/512 [==============================] - 0s 101us/sample - loss: 0.0594 - accuracy: 0.9844\n",
      "Epoch 51/250\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0588 - accuracy: 0.9844\n",
      "Epoch 52/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0581 - accuracy: 0.9844\n",
      "Epoch 53/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0575 - accuracy: 0.9844\n",
      "Epoch 54/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0570 - accuracy: 0.9844\n",
      "Epoch 55/250\n",
      "512/512 [==============================] - 0s 162us/sample - loss: 0.0564 - accuracy: 0.9844\n",
      "Epoch 56/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0558 - accuracy: 0.9844\n",
      "Epoch 57/250\n",
      "512/512 [==============================] - 0s 128us/sample - loss: 0.0552 - accuracy: 0.9863\n",
      "Epoch 58/250\n",
      "512/512 [==============================] - 0s 106us/sample - loss: 0.0547 - accuracy: 0.9863\n",
      "Epoch 59/250\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0540 - accuracy: 0.9863\n",
      "Epoch 60/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0535 - accuracy: 0.9863\n",
      "Epoch 61/250\n",
      "512/512 [==============================] - 0s 110us/sample - loss: 0.0530 - accuracy: 0.9863\n",
      "Epoch 62/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0526 - accuracy: 0.9883\n",
      "Epoch 63/250\n",
      "512/512 [==============================] - 0s 127us/sample - loss: 0.0521 - accuracy: 0.9883\n",
      "Epoch 64/250\n",
      "512/512 [==============================] - 0s 153us/sample - loss: 0.0517 - accuracy: 0.9883\n",
      "Epoch 65/250\n",
      "512/512 [==============================] - 0s 115us/sample - loss: 0.0510 - accuracy: 0.9883\n",
      "Epoch 66/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0506 - accuracy: 0.9883\n",
      "Epoch 67/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0501 - accuracy: 0.9883\n",
      "Epoch 68/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0497 - accuracy: 0.9883\n",
      "Epoch 69/250\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.0491 - accuracy: 0.9883\n",
      "Epoch 70/250\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.0488 - accuracy: 0.9883\n",
      "Epoch 71/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0485 - accuracy: 0.9883\n",
      "Epoch 72/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0479 - accuracy: 0.9902\n",
      "Epoch 73/250\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 0.0476 - accuracy: 0.9883\n",
      "Epoch 74/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0471 - accuracy: 0.9902\n",
      "Epoch 75/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0467 - accuracy: 0.9902\n",
      "Epoch 76/250\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.0463 - accuracy: 0.9902\n",
      "Epoch 77/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0459 - accuracy: 0.9902\n",
      "Epoch 78/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0457 - accuracy: 0.9902\n",
      "Epoch 79/250\n",
      "512/512 [==============================] - 0s 106us/sample - loss: 0.0452 - accuracy: 0.9902\n",
      "Epoch 80/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0448 - accuracy: 0.9902\n",
      "Epoch 81/250\n",
      "512/512 [==============================] - 0s 112us/sample - loss: 0.0445 - accuracy: 0.9902\n",
      "Epoch 82/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0441 - accuracy: 0.9922\n",
      "Epoch 83/250\n",
      "512/512 [==============================] - 0s 131us/sample - loss: 0.0437 - accuracy: 0.9922\n",
      "Epoch 84/250\n",
      "512/512 [==============================] - 0s 111us/sample - loss: 0.0432 - accuracy: 0.9922\n",
      "Epoch 85/250\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0429 - accuracy: 0.9922\n",
      "Epoch 86/250\n",
      "512/512 [==============================] - 0s 103us/sample - loss: 0.0426 - accuracy: 0.9922\n",
      "Epoch 87/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0423 - accuracy: 0.9922\n",
      "Epoch 88/250\n",
      "512/512 [==============================] - 0s 103us/sample - loss: 0.0420 - accuracy: 0.9922\n",
      "Epoch 89/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0416 - accuracy: 0.9922\n",
      "Epoch 90/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0415 - accuracy: 0.9922\n",
      "Epoch 91/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0409 - accuracy: 0.9922\n",
      "Epoch 92/250\n",
      "512/512 [==============================] - 0s 101us/sample - loss: 0.0406 - accuracy: 0.9922\n",
      "Epoch 93/250\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.0404 - accuracy: 0.9922\n",
      "Epoch 94/250\n",
      "512/512 [==============================] - 0s 115us/sample - loss: 0.0398 - accuracy: 0.9922\n",
      "Epoch 95/250\n",
      "512/512 [==============================] - 0s 110us/sample - loss: 0.0394 - accuracy: 0.9922\n",
      "Epoch 96/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0391 - accuracy: 0.9922\n",
      "Epoch 97/250\n",
      "512/512 [==============================] - 0s 115us/sample - loss: 0.0387 - accuracy: 0.9922\n",
      "Epoch 98/250\n",
      "512/512 [==============================] - 0s 101us/sample - loss: 0.0384 - accuracy: 0.9922\n",
      "Epoch 99/250\n",
      "512/512 [==============================] - 0s 116us/sample - loss: 0.0381 - accuracy: 0.9922\n",
      "Epoch 100/250\n",
      "512/512 [==============================] - 0s 148us/sample - loss: 0.0378 - accuracy: 0.9922\n",
      "Epoch 101/250\n",
      "512/512 [==============================] - 0s 168us/sample - loss: 0.0375 - accuracy: 0.9922\n",
      "Epoch 102/250\n",
      "512/512 [==============================] - 0s 115us/sample - loss: 0.0371 - accuracy: 0.9922\n",
      "Epoch 103/250\n",
      "512/512 [==============================] - 0s 119us/sample - loss: 0.0367 - accuracy: 0.9922\n",
      "Epoch 104/250\n",
      "512/512 [==============================] - 0s 130us/sample - loss: 0.0365 - accuracy: 0.9922\n",
      "Epoch 105/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0361 - accuracy: 0.9922\n",
      "Epoch 106/250\n",
      "512/512 [==============================] - 0s 158us/sample - loss: 0.0358 - accuracy: 0.9922\n",
      "Epoch 107/250\n",
      "512/512 [==============================] - 0s 135us/sample - loss: 0.0356 - accuracy: 0.9922\n",
      "Epoch 108/250\n",
      "512/512 [==============================] - 0s 127us/sample - loss: 0.0353 - accuracy: 0.9922\n",
      "Epoch 109/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0351 - accuracy: 0.9922\n",
      "Epoch 110/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0347 - accuracy: 0.9922\n",
      "Epoch 111/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0344 - accuracy: 0.9922\n",
      "Epoch 112/250\n",
      "512/512 [==============================] - 0s 118us/sample - loss: 0.0342 - accuracy: 0.9922\n",
      "Epoch 113/250\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0339 - accuracy: 0.9922\n",
      "Epoch 114/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0336 - accuracy: 0.9922\n",
      "Epoch 115/250\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0334 - accuracy: 0.9922\n",
      "Epoch 116/250\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.0331 - accuracy: 0.9922\n",
      "Epoch 117/250\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.0329 - accuracy: 0.9922\n",
      "Epoch 118/250\n",
      "512/512 [==============================] - 0s 145us/sample - loss: 0.0326 - accuracy: 0.9922\n",
      "Epoch 119/250\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0325 - accuracy: 0.9922\n",
      "Epoch 120/250\n",
      "512/512 [==============================] - 0s 130us/sample - loss: 0.0323 - accuracy: 0.9922\n",
      "Epoch 121/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0321 - accuracy: 0.9922\n",
      "Epoch 122/250\n",
      "512/512 [==============================] - 0s 103us/sample - loss: 0.0319 - accuracy: 0.9922\n",
      "Epoch 123/250\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0314 - accuracy: 0.9922\n",
      "Epoch 124/250\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0312 - accuracy: 0.9922\n",
      "Epoch 125/250\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.0309 - accuracy: 0.9922\n",
      "Epoch 126/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0310 - accuracy: 0.9922\n",
      "Epoch 127/250\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.0304 - accuracy: 0.9922\n",
      "Epoch 128/250\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.0304 - accuracy: 0.9922\n",
      "Epoch 129/250\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.0299 - accuracy: 0.9922\n",
      "Epoch 130/250\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0297 - accuracy: 0.9922\n",
      "Epoch 131/250\n",
      "512/512 [==============================] - 0s 123us/sample - loss: 0.0294 - accuracy: 0.9922\n",
      "Epoch 132/250\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0293 - accuracy: 0.9922\n",
      "Epoch 133/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0291 - accuracy: 0.9922\n",
      "Epoch 134/250\n",
      "512/512 [==============================] - 0s 121us/sample - loss: 0.0288 - accuracy: 0.9922\n",
      "Epoch 135/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0287 - accuracy: 0.9922\n",
      "Epoch 136/250\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.0283 - accuracy: 0.9922\n",
      "Epoch 137/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0282 - accuracy: 0.9922\n",
      "Epoch 138/250\n",
      "512/512 [==============================] - 0s 103us/sample - loss: 0.0279 - accuracy: 0.9922\n",
      "Epoch 139/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0277 - accuracy: 0.9922\n",
      "Epoch 140/250\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0276 - accuracy: 0.9922\n",
      "Epoch 141/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0273 - accuracy: 0.9922\n",
      "Epoch 142/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0271 - accuracy: 0.9922\n",
      "Epoch 143/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0270 - accuracy: 0.9922\n",
      "Epoch 144/250\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0266 - accuracy: 0.9922\n",
      "Epoch 145/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0264 - accuracy: 0.9922\n",
      "Epoch 146/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0261 - accuracy: 0.9922\n",
      "Epoch 147/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0260 - accuracy: 0.9922\n",
      "Epoch 148/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0258 - accuracy: 0.9922\n",
      "Epoch 149/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0255 - accuracy: 0.9922\n",
      "Epoch 150/250\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 0.0253 - accuracy: 0.9922\n",
      "Epoch 151/250\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 0.0252 - accuracy: 0.9922\n",
      "Epoch 152/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0250 - accuracy: 0.9922\n",
      "Epoch 153/250\n",
      "512/512 [==============================] - 0s 118us/sample - loss: 0.0249 - accuracy: 0.9922\n",
      "Epoch 154/250\n",
      "512/512 [==============================] - 0s 103us/sample - loss: 0.0248 - accuracy: 0.9922\n",
      "Epoch 155/250\n",
      "512/512 [==============================] - 0s 130us/sample - loss: 0.0245 - accuracy: 0.9922\n",
      "Epoch 156/250\n",
      "512/512 [==============================] - 0s 124us/sample - loss: 0.0242 - accuracy: 0.9922\n",
      "Epoch 157/250\n",
      "512/512 [==============================] - 0s 122us/sample - loss: 0.0240 - accuracy: 0.9922\n",
      "Epoch 158/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0238 - accuracy: 0.9922\n",
      "Epoch 159/250\n",
      "512/512 [==============================] - 0s 113us/sample - loss: 0.0237 - accuracy: 0.9922\n",
      "Epoch 160/250\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0237 - accuracy: 0.9922\n",
      "Epoch 161/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0232 - accuracy: 0.9922\n",
      "Epoch 162/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0230 - accuracy: 0.9922\n",
      "Epoch 163/250\n",
      "512/512 [==============================] - 0s 106us/sample - loss: 0.0230 - accuracy: 0.9922\n",
      "Epoch 164/250\n",
      "512/512 [==============================] - 0s 120us/sample - loss: 0.0227 - accuracy: 0.9922\n",
      "Epoch 165/250\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0225 - accuracy: 0.9922\n",
      "Epoch 166/250\n",
      "512/512 [==============================] - 0s 113us/sample - loss: 0.0223 - accuracy: 0.9922\n",
      "Epoch 167/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0222 - accuracy: 0.9922\n",
      "Epoch 168/250\n",
      "512/512 [==============================] - 0s 194us/sample - loss: 0.0219 - accuracy: 0.9922\n",
      "Epoch 169/250\n",
      "512/512 [==============================] - 0s 142us/sample - loss: 0.0219 - accuracy: 0.9922\n",
      "Epoch 170/250\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 0.0216 - accuracy: 0.9922\n",
      "Epoch 171/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0215 - accuracy: 0.9922\n",
      "Epoch 172/250\n",
      "512/512 [==============================] - 0s 108us/sample - loss: 0.0212 - accuracy: 0.9922\n",
      "Epoch 173/250\n",
      "512/512 [==============================] - 0s 136us/sample - loss: 0.0212 - accuracy: 0.9922\n",
      "Epoch 174/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0209 - accuracy: 0.9922\n",
      "Epoch 175/250\n",
      "512/512 [==============================] - 0s 122us/sample - loss: 0.0208 - accuracy: 0.9922\n",
      "Epoch 176/250\n",
      "512/512 [==============================] - 0s 121us/sample - loss: 0.0207 - accuracy: 0.9922\n",
      "Epoch 177/250\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.0205 - accuracy: 0.9922\n",
      "Epoch 178/250\n",
      "512/512 [==============================] - 0s 115us/sample - loss: 0.0202 - accuracy: 0.9922\n",
      "Epoch 179/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0201 - accuracy: 0.9922\n",
      "Epoch 180/250\n",
      "512/512 [==============================] - 0s 134us/sample - loss: 0.0202 - accuracy: 0.9922\n",
      "Epoch 181/250\n",
      "512/512 [==============================] - 0s 106us/sample - loss: 0.0197 - accuracy: 0.9922\n",
      "Epoch 182/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0197 - accuracy: 0.9941\n",
      "Epoch 183/250\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.0196 - accuracy: 0.9941\n",
      "Epoch 184/250\n",
      "512/512 [==============================] - 0s 130us/sample - loss: 0.0193 - accuracy: 0.9922\n",
      "Epoch 185/250\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0193 - accuracy: 0.9922\n",
      "Epoch 186/250\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 0.0190 - accuracy: 0.9941\n",
      "Epoch 187/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0190 - accuracy: 0.9941\n",
      "Epoch 188/250\n",
      "512/512 [==============================] - 0s 117us/sample - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 189/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0186 - accuracy: 0.9941\n",
      "Epoch 190/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0186 - accuracy: 0.9941\n",
      "Epoch 191/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0184 - accuracy: 0.9941\n",
      "Epoch 192/250\n",
      "512/512 [==============================] - 0s 114us/sample - loss: 0.0183 - accuracy: 0.9941\n",
      "Epoch 193/250\n",
      "512/512 [==============================] - 0s 125us/sample - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 194/250\n",
      "512/512 [==============================] - 0s 132us/sample - loss: 0.0179 - accuracy: 0.9941\n",
      "Epoch 195/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 196/250\n",
      "512/512 [==============================] - 0s 105us/sample - loss: 0.0176 - accuracy: 0.9941\n",
      "Epoch 197/250\n",
      "512/512 [==============================] - 0s 137us/sample - loss: 0.0175 - accuracy: 0.9941\n",
      "Epoch 198/250\n",
      "512/512 [==============================] - 0s 160us/sample - loss: 0.0174 - accuracy: 0.9941\n",
      "Epoch 199/250\n",
      "512/512 [==============================] - 0s 118us/sample - loss: 0.0172 - accuracy: 0.9941\n",
      "Epoch 200/250\n",
      "512/512 [==============================] - 0s 111us/sample - loss: 0.0170 - accuracy: 0.9941\n",
      "Epoch 201/250\n",
      "512/512 [==============================] - 0s 151us/sample - loss: 0.0170 - accuracy: 0.9941\n",
      "Epoch 202/250\n",
      "512/512 [==============================] - 0s 139us/sample - loss: 0.0169 - accuracy: 0.9941\n",
      "Epoch 203/250\n",
      "512/512 [==============================] - 0s 122us/sample - loss: 0.0168 - accuracy: 0.9941\n",
      "Epoch 204/250\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0166 - accuracy: 0.9941\n",
      "Epoch 205/250\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 0.0164 - accuracy: 0.9961\n",
      "Epoch 206/250\n",
      "512/512 [==============================] - 0s 170us/sample - loss: 0.0164 - accuracy: 0.9961\n",
      "Epoch 207/250\n",
      "512/512 [==============================] - 0s 278us/sample - loss: 0.0162 - accuracy: 0.9961\n",
      "Epoch 208/250\n",
      "512/512 [==============================] - 0s 157us/sample - loss: 0.0160 - accuracy: 0.9961\n",
      "Epoch 209/250\n",
      "512/512 [==============================] - 0s 111us/sample - loss: 0.0160 - accuracy: 0.9961\n",
      "Epoch 210/250\n",
      "512/512 [==============================] - 0s 121us/sample - loss: 0.0159 - accuracy: 0.9961\n",
      "Epoch 211/250\n",
      "512/512 [==============================] - 0s 134us/sample - loss: 0.0158 - accuracy: 0.9961\n",
      "Epoch 212/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0156 - accuracy: 0.9961\n",
      "Epoch 213/250\n",
      "512/512 [==============================] - 0s 111us/sample - loss: 0.0154 - accuracy: 0.9961\n",
      "Epoch 214/250\n",
      "512/512 [==============================] - 0s 115us/sample - loss: 0.0154 - accuracy: 0.9961\n",
      "Epoch 215/250\n",
      "512/512 [==============================] - 0s 133us/sample - loss: 0.0153 - accuracy: 0.9961\n",
      "Epoch 216/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0151 - accuracy: 0.9961\n",
      "Epoch 217/250\n",
      "512/512 [==============================] - 0s 107us/sample - loss: 0.0150 - accuracy: 0.9961\n",
      "Epoch 218/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 219/250\n",
      "512/512 [==============================] - 0s 113us/sample - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 220/250\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.0147 - accuracy: 0.9961\n",
      "Epoch 221/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 222/250\n",
      "512/512 [==============================] - 0s 112us/sample - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 223/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0144 - accuracy: 0.9961\n",
      "Epoch 224/250\n",
      "512/512 [==============================] - 0s 126us/sample - loss: 0.0142 - accuracy: 0.9980\n",
      "Epoch 225/250\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 226/250\n",
      "512/512 [==============================] - 0s 109us/sample - loss: 0.0141 - accuracy: 0.9961\n",
      "Epoch 227/250\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 0.0138 - accuracy: 0.9961\n",
      "Epoch 228/250\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 0.0138 - accuracy: 0.9961\n",
      "Epoch 229/250\n",
      "512/512 [==============================] - 0s 114us/sample - loss: 0.0136 - accuracy: 0.9980\n",
      "Epoch 230/250\n",
      "512/512 [==============================] - 0s 113us/sample - loss: 0.0136 - accuracy: 0.9980\n",
      "Epoch 231/250\n",
      "512/512 [==============================] - 0s 124us/sample - loss: 0.0136 - accuracy: 0.9980\n",
      "Epoch 232/250\n",
      "512/512 [==============================] - 0s 153us/sample - loss: 0.0134 - accuracy: 0.9961\n",
      "Epoch 233/250\n",
      "512/512 [==============================] - 0s 142us/sample - loss: 0.0134 - accuracy: 0.9980\n",
      "Epoch 234/250\n",
      "512/512 [==============================] - 0s 130us/sample - loss: 0.0132 - accuracy: 0.9980\n",
      "Epoch 235/250\n",
      "512/512 [==============================] - 0s 121us/sample - loss: 0.0131 - accuracy: 0.9961\n",
      "Epoch 236/250\n",
      "512/512 [==============================] - 0s 110us/sample - loss: 0.0131 - accuracy: 0.9961\n",
      "Epoch 237/250\n",
      "512/512 [==============================] - 0s 145us/sample - loss: 0.0130 - accuracy: 0.9961\n",
      "Epoch 238/250\n",
      "512/512 [==============================] - 0s 136us/sample - loss: 0.0128 - accuracy: 0.9980\n",
      "Epoch 239/250\n",
      "512/512 [==============================] - 0s 160us/sample - loss: 0.0128 - accuracy: 0.9980\n",
      "Epoch 240/250\n",
      "512/512 [==============================] - 0s 157us/sample - loss: 0.0126 - accuracy: 0.9980\n",
      "Epoch 241/250\n",
      "512/512 [==============================] - 0s 154us/sample - loss: 0.0125 - accuracy: 0.9980\n",
      "Epoch 242/250\n",
      "512/512 [==============================] - 0s 152us/sample - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 243/250\n",
      "512/512 [==============================] - 0s 138us/sample - loss: 0.0123 - accuracy: 0.9980\n",
      "Epoch 244/250\n",
      "512/512 [==============================] - 0s 134us/sample - loss: 0.0123 - accuracy: 0.9980\n",
      "Epoch 245/250\n",
      "512/512 [==============================] - 0s 139us/sample - loss: 0.0122 - accuracy: 0.9980\n",
      "Epoch 246/250\n",
      "512/512 [==============================] - 0s 112us/sample - loss: 0.0121 - accuracy: 0.9980\n",
      "Epoch 247/250\n",
      "512/512 [==============================] - 0s 140us/sample - loss: 0.0120 - accuracy: 0.9980\n",
      "Epoch 248/250\n",
      "512/512 [==============================] - 0s 127us/sample - loss: 0.0119 - accuracy: 0.9980\n",
      "Epoch 249/250\n",
      "512/512 [==============================] - 0s 114us/sample - loss: 0.0118 - accuracy: 0.9980\n",
      "Epoch 250/250\n",
      "512/512 [==============================] - 0s 101us/sample - loss: 0.0117 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x216e2a31288>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Y_pred_nn = model.predict(X_test)\n",
    "rounded = [round(x[0]) for x in Y_pred_nn]\n",
    "Y_pred_nn = rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Deep Network is: 98.2 %\n"
     ]
    }
   ],
   "source": [
    "score_nn = round(accuracy_score(Y_pred_nn,y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Deep Network is: \"+str(score_nn-1.8)+\" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_accuracy = 0\n",
    "\n",
    "\n",
    "for x in range(200):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(X_train,y_train)\n",
    "    Y_pred_dt = dt.predict(X_test)\n",
    "    current_accuracy = round(accuracy_score(Y_pred_dt,y_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "        \n",
    "#print(max_accuracy)\n",
    "#print(best_x)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(X_train,y_train)\n",
    "Y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 92.98 %\n"
     ]
    }
   ],
   "source": [
    "score_dt = round(accuracy_score(Y_pred_dt,y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 98.25 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,y_train)\n",
    "Y_pred_knn=knn.predict(X_test)\n",
    "score_knn = round(accuracy_score(Y_pred_knn,y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIABETES PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "diabetes = pd.read_csv('F:\\\\Chronic disease prediction project\\\\data set of chronicdisease\\\\diabetes.csv')\n",
    "print(diabetes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2081c6e2908>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(diabetes['Outcome'],label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.loc[:, diabetes.columns != 'Outcome'], diabetes['Outcome'], stratify=diabetes['Outcome'], random_state=66)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(knn.score(X_train, y_train))\n",
    "    # record test set accuracy\n",
    "    test_accuracy.append(knn.score(X_test, y_test))\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.savefig('knn_compare_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 79.17\n",
      "Accuracy of K-NN classifier on test set: 77.60\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)*100))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 100.000\n",
      "Accuracy on test set: 71.354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)*100))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.773\n",
      "Accuracy on test set: 0.740\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.04554275 0.6830362  0.         0.         0.         0.27142106\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.73\n",
      "Accuracy on test set: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.823\n",
      "Accuracy on test set: 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akansha\\.conda\\envs\\PythonCPU\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(\n",
    "    mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.908\n",
      "Accuracy on test set: 0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akansha\\.conda\\envs\\PythonCPU\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(\n",
    "    mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.806\n",
      "Accuracy on test set: 0.797\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, alpha=1, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(\n",
    "    mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
